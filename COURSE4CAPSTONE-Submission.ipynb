{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Submission\n",
    "\n",
    "This notebook will be your project submission. All tasks will be listed in the order of the Courses that they appear in. The tasks will be the same as in the Capstone Example Notebook, but in this submission you ___MUST___ use another dataset. Failure to do so will result in a large penalty to your grade in this course.\n",
    "\n",
    "## Finding your dataset\n",
    "\n",
    "Take some time to find an interesting dataset! There is a reading discussing various places where datasets can be found, but if you are able to process it, go ahead and use it! Do note, for some tasks in this project, each entry will need 3+ attributes, so keep that in mind when finding datasets. After you have found your dataset, the tasks will continue as in the Example Notebook. You will be graded based on the tasks and your results. Best of luck!\n",
    "\n",
    "### As Reviewer: \n",
    "Your job will be to verify the calculations made at each \"TODO\" labeled throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Imports\n",
    "\n",
    "In the next cell we will give you all of the imports you should need to do your project. Feel free to add more if you would like, but these should be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from nltk.stem.porter import PorterStemmer # Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Processing\n",
    "\n",
    "### TODO 1: Read the data and Fill your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset used here is the Amazon US Reviews Gift Card Category acquired from \n",
    "# (https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz)\n",
    "\n",
    "file = 'amazon_reviews_us_Gift_Card_v1_00.tsv'\n",
    "f = open(file, 'rt')\n",
    "header = f.readline().strip().split('\\t')\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    line = line.split('\\t') # splitting by tab\n",
    "    d = dict(zip(header, line)) # creating key-value pairs for each tuple    \n",
    "    # converting data types to integer\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    d['verified_purchase'] = d['verified_purchase'] == 'Y' \n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'marketplace': 'US',\n",
       " 'customer_id': '24371595',\n",
       " 'review_id': 'R27ZP1F1CD0C3Y',\n",
       " 'product_id': 'B004LLIL5A',\n",
       " 'product_parent': '346014806',\n",
       " 'product_title': 'Amazon eGift Card - Celebrate',\n",
       " 'product_category': 'Gift Card',\n",
       " 'star_rating': 5,\n",
       " 'helpful_votes': 0,\n",
       " 'total_votes': 0,\n",
       " 'vine': 'N',\n",
       " 'verified_purchase': True,\n",
       " 'review_headline': 'Five Stars',\n",
       " 'review_body': 'Great birthday gift for a young adult.',\n",
       " 'review_date': '2015-08-31\\n'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Split the data into a Training and Testing set\n",
    "\n",
    "First shuffle your data, then split your data. Have Training be the first 80%, and testing be the remaining 20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119268 29818\n"
     ]
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "\n",
    "# establishing a 80/20 split for train/test\n",
    "train_set = dataset[:N*8//10]\n",
    "test_set = dataset[N*8//10:]\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now delete your dataset\n",
    "You don't want any of your answers to come from your original dataset any longer, but rather your Training Set, this will help you to not make any mistakes later on, especialy when referencing the checkpoint solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3: Extracting Basic Statistics\n",
    "\n",
    "Next you need to answer some questions through any means (i.e. write a function or just find the answer) all based on the __Training Set:__\n",
    "1. How many entries are in your dataset?\n",
    "2. Pick a non-trivial attribute (i.e. verified purchases in example), what percentage of your data has this atttribute?\n",
    "3. Pick another different non-trivial attribute, what percentage of your data share both attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in our training set ->  119268\n",
      "Percentage value of verified purchases ->  96.52631049401347\n",
      "Percentage value of total votes ->  0.8233558037361237\n"
     ]
    }
   ],
   "source": [
    "# manipulating our data into a pandas DataFrame\n",
    "train_df = pd.DataFrame(train_set)\n",
    "print('Number of entries in our training set -> ', (train_df.shape[0]))\n",
    "\n",
    "# Calculating percentage of verified purchases from total purchases\n",
    "partTwo = (train_df[train_df['verified_purchase'] == True].shape[0] / train_df.shape[0]) * 100\n",
    "print('Percentage value of verified purchases -> ', partTwo)\n",
    "\n",
    "# Total Votes as a percentage\n",
    "partThree = (train_df[train_df['total_votes']>2].shape[0] / train_df.shape[0]) * 100\n",
    "print('Percentage value of total votes -> ', partThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Classification\n",
    "\n",
    "Next you will use our knowledge of classification to extract features and make predictions based on them. Here you will be using a Logistic Regression Model, keep this in mind so you know where to get help from.\n",
    "\n",
    "### TODO 1: Define the feature function\n",
    "\n",
    "This implementation will be based on ___any two___ attributes from your dataset. You will be using these two attributes to predict a third. Hint: Remember the offset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = [1, d['total_votes'], (d['helpful_votes'])]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Fit your model\n",
    "\n",
    "1. Create your __Feature Vector__ based on your feature function defined above. \n",
    "2. Create your __Label Vector__ based on the \"verified purchase\" column of your training set.\n",
    "3. Define your model as a __Logistic Regression__ model.\n",
    "4. Fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [feature(d) for d in train_set]\n",
    "X_test = [feature(d) for d in test_set]\n",
    "y_train = [d['verified_purchase'] for d in train_set]\n",
    "y_test = [d['verified_purchase'] for d in test_set]\n",
    "\n",
    "# fit your model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3: Compute Accuracy of Your Model\n",
    "\n",
    "1. Make __Predictions__ based on your model.\n",
    "2. Compute the __Accuracy__ of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      0.01      0.01      8901\n",
      "        True       0.70      1.00      0.82     20917\n",
      "\n",
      "    accuracy                           0.70     29818\n",
      "   macro avg       0.59      0.50      0.42     29818\n",
      "weighted avg       0.64      0.70      0.58     29818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "accuracy = classification_report(y_true = y_test, y_pred = prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Regression\n",
    "\n",
    "In this section you will start by working though two examples of altering features to further differentiate. Then you will work through how to evaluate a Regularaized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"amazon_reviews_us_Gift_Card_v1_00.tsv\"\n",
    "\n",
    "f = open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "reg_dataset = []\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    reg_dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Unique Words in a Sample Set\n",
    "\n",
    "We are going to work with a new dataset here, as such we are going to take a smaller portion of the set and call it a Sample Set. This is because stemming on the normal training set will take a very long time. (Feel free to change sampleSet -> reg_dataset if you would like to see the difference for yourself)\n",
    "\n",
    "1. Count the number of unique words found within the 'review body' portion of the sample set defined below, making sure to __Ignore Punctuation and Capitalization__.\n",
    "2. Count the number of unique words found within the 'review body' portion of the sample set defined below, this time with use of __Stemming,__ __Ignoring Puctuation,__ ___and___ __Capitalization__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "wordCountStem = defaultdict(int)\n",
    "stemmer = PorterStemmer() #use stemmer.stem(stuff)\n",
    "\n",
    "#SampleSet and y vector given\n",
    "sampleSet = reg_dataset[:2*len(reg_dataset)//10]\n",
    "y_reg = [d['star_rating'] for d in sampleSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Stemming: 10765\n",
      "with Stemming: 8389\n"
     ]
    }
   ],
   "source": [
    "for d in sampleSet:\n",
    "    r = \"\".join([c for c in d[\"review_body\"].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] += 1\n",
    "        \n",
    "for d in sampleSet:\n",
    "    r = \"\".join([c for c in d[\"review_body\"].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        wordCountStem[w] += 1\n",
    "\n",
    "print ('No Stemming:', len(wordCount))\n",
    "print ('with Stemming:', len(wordCountStem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Evaluating Classifiers\n",
    "\n",
    "1. Given the feature function and your counts vector, __Define__ your X_reg vector. (This being the X vector, simply labeled for the Regression model)\n",
    "2. __Fit__ your model using a __Ridge Model__ with (alpha = 1.0, fit_intercept = True).\n",
    "3. Using your model, __Make your Predictions__.\n",
    "4. Find the __MSE__ between your predictions and your y_reg vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_reg(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    return feat\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "#Note: increasing the size of the dictionary may require a lot of memory\n",
    "words = [x[1] for x in counts[:1000]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3648830231415904\n"
     ]
    }
   ],
   "source": [
    "X = [feature_reg(d) for d in sampleSet]\n",
    "y = [d[\"star_rating\"] for d in sampleSet]\n",
    "model = linear_model.Ridge(1.0, fit_intercept=True) #1.0 regularization strength like lambda\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "print ('MSE:', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Recommendation Systems\n",
    "\n",
    "For your final task, you will use your knowledge of simple similarity-based recommender systems to make calculate the most similar items.\n",
    "\n",
    "The next cell contains some starter code that you will need for your tasks in this section.\n",
    "Notice you should be back to using your __trainingSet__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Fill your Dictionaries\n",
    "\n",
    "1. For each entry in your training set, fill your default dictionaries (defined above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemNames = {}\n",
    "\n",
    "for d in train_set:\n",
    "    user,item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "def mostSimilar(identifier, n):\n",
    "    similarities = []\n",
    "    identifier_list = []\n",
    "    users = usersPerItem[identifier]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == identifier: continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    for i in similarities:\n",
    "        identifier_list.append(i[1])\n",
    "    print(identifier_list[:n])\n",
    "    return similarities[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: Fill your Dictionaries\n",
    "\n",
    "1. Calculate the __10__ most similar entries to the __first__ entry in your dataset, using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID:  B004LLIKVU \n",
      "Product title: Amazon.com eGift Cards\n"
     ]
    }
   ],
   "source": [
    "query = train_set[1]['product_id']\n",
    "\n",
    "print(\"Product ID: \", query, \"\\nProduct title:\", itemNames[query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B00IX1I3G6', 'B004KNWWO0', 'B007V6EVY2', 'BT00DDC7CE', 'B004KNWX3U', 'B00A44A3Y0', 'B00G4IWEZG', 'B004W8D102', 'BT00CTOY20', 'BT00CTOYC0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.01746373781880166, 'B00IX1I3G6'),\n",
       " (0.006271339976308271, 'B004KNWWO0'),\n",
       " (0.0007555204505649232, 'B007V6EVY2'),\n",
       " (0.0005087394164032123, 'BT00DDC7CE'),\n",
       " (0.0003592083048960092, 'B004KNWX3U'),\n",
       " (0.00031968173906866054, 'B00A44A3Y0'),\n",
       " (0.0003191602539097131, 'B00G4IWEZG'),\n",
       " (0.000291587694999271, 'B004W8D102'),\n",
       " (0.0002904443799012489, 'BT00CTOY20'),\n",
       " (0.0002547492539486134, 'BT00CTOYC0')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilar(query, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished!\n",
    "\n",
    "Congratulations! You are now ready to submit your work. Once you have submitted make sure to get started on your peer reviews!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
